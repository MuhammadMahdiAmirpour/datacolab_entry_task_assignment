{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Mounting the google drive**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "wwhE9EJp52jF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# you need to uncomment this line when you want to run this code on google colab and load you data from google drive\n",
    "from google.colab import drive\n",
    "# Mount Google Drive as a local file system\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "qe3gUvLo5ojv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Installing the needed libraries**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "TVSIFUqT6KoF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAR6gn0ZJOSE"
   },
   "outputs": [],
   "source": [
    "!pip install diffusers torch accelerate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Importing the needed libraries**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "jxL4yVmO86T6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QUBI2IljUzM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AmusedPipeline\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Double check**"
   ],
   "metadata": {
    "id": "GRgYZEJW9JsB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Install the accelerate library\n",
    "!pip install --upgrade accelerate\n",
    "\n",
    "# Import the accelerate library\n",
    "from accelerate import cpu_offload\n",
    "\n",
    "# Mount Google Drive\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "except Exception as e:\n",
    "    print(f\"Error mounting Google Drive: {e}\")\n",
    "    print(\"Attempting to forcibly remount...\")\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "id": "Uv01AQlTCGYM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Set up the environment**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "mbHHxyQkGU06"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the CUDA allocation configuration to use expandable segments\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Define global variables for input and output file paths, you can change this if you have your custom dataset\n",
    "INPUT_FILE_PATH = 'path'\n",
    "OUTPUT_DIR = 'path'"
   ],
   "metadata": {
    "id": "6_9hAus2GZek"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Generate the images using paralleliztion**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "85QZZJkbGbll"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_existing_image_filenames() -> set:\n",
    "    \"\"\"\n",
    "    Get a set of existing image filenames in the output directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    return set([f.split('.')[0] for f in os.listdir(OUTPUT_DIR) if f.endswith('.png')])\n",
    "\n",
    "\n",
    "class ImageGenerator:\n",
    "    \"\"\"\n",
    "    A class responsible for generating images from text prompts using the Amused Diffusion model.\n",
    "    \"\"\"\n",
    "    def __init__(self, device: torch.device):\n",
    "        self.device = device\n",
    "        self.pipe = self.load_amused_pipeline()\n",
    "        self.existing_images = get_existing_image_filenames()\n",
    "\n",
    "    def load_amused_pipeline(self) -> AmusedPipeline:\n",
    "        \"\"\"\n",
    "        Load the pre-trained Amused Diffusion model and move it to the specified device.\n",
    "        \"\"\"\n",
    "        pipe = AmusedPipeline.from_pretrained(\"amused/amused-256\", device_map=\"auto\", low_cpu_mem_usage=True)\n",
    "        return pipe.to(self.device)\n",
    "\n",
    "    def generate_image(self, freebase_id: str, prompt: str) -> None:\n",
    "        \"\"\"\n",
    "        Generate an image from the given text prompt and save it with the freebaseID as the filename.\n",
    "\n",
    "        If the image for the current freebaseID already exists, print a message and return.\n",
    "        \"\"\"\n",
    "        # Replace forward slashes with underscores in the freebaseID\n",
    "        cleaned_freebase_id = re.sub(r'[/]', '_', freebase_id)\n",
    "\n",
    "        # Check if the image with the current freebaseID already exists\n",
    "        if cleaned_freebase_id in self.existing_images:\n",
    "            print(f\"Image for {cleaned_freebase_id} already exists, skipping...\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Generate the image using the Amused Diffusion model\n",
    "            image = self.pipe(prompt, negative_prompt=\"low quality, ugly\", generator=torch.manual_seed(0)).images[0]\n",
    "            image_path = os.path.join(OUTPUT_DIR, f\"{cleaned_freebase_id}.png\")\n",
    "            image.save(image_path)\n",
    "            print(f\"Image saved: {image_path}\")\n",
    "            sys.stdout.flush()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image for {cleaned_freebase_id}: {e}\")\n",
    "\n",
    "class DataManager:\n",
    "    \"\"\"\n",
    "    A class responsible for managing the input data and the image generation process.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_file_path: str):\n",
    "        self.input_file_path = input_file_path\n",
    "\n",
    "    def load_input_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load the input data from the specified file path.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The input DataFrame containing the text prompts and freebaseIDs.\n",
    "        \"\"\"\n",
    "        column_names = [\"length\", \"freebase_id\", \"book_name\", \"author_name\", \"date\", \"freebase_id_json\", \"summary\"]\n",
    "        data = pd.read_csv(self.input_file_path, sep=\"\\t\", header=None, names=column_names)\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main entry point of the application.\n",
    "\n",
    "    1. Create a DataManager instance to handle the input data\n",
    "    2. Load the input data\n",
    "    3. Create an ImageGenerator instance and start the parallel image generation process\n",
    "    \"\"\"\n",
    "    try:\n",
    "        manager = DataManager(INPUT_FILE_PATH)\n",
    "        df = manager.load_input_data()\n",
    "\n",
    "        # Create an ImageGenerator instance and start the parallel image generation process\n",
    "        generator = ImageGenerator(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(generator.generate_image, row['freebase_id'], row['summary']) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating images\")]\n",
    "            concurrent.futures.wait(futures)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "id": "GV2vtyvIGlLj"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
